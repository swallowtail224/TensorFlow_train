{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\ganda\\conda\\tensorflow_test\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function fetch_mldata is deprecated; fetch_mldata was deprecated in version 0.20 and will be removed in version 0.22\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "G:\\ganda\\conda\\tensorflow_test\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function mldata_filename is deprecated; mldata_filename was deprecated in version 0.20 and will be removed in version 0.22\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "mnist = datasets.fetch_mldata('MNIST original', data_home = '.')\n",
    "\n",
    "n = len(mnist.data)\n",
    "N = 10000\n",
    "\n",
    "indices = np.random.permutation(range(n))[:N]\n",
    "X = mnist.data[indices]\n",
    "y = mnist.target[indices]\n",
    "Y = np.eye(10)[y.astype(int)]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 1.9578 - acc: 0.3584\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 1.2886 - acc: 0.6821\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.0057 - acc: 0.7705\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.8464 - acc: 0.8143\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.7443 - acc: 0.8394\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.6704 - acc: 0.8556\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.6101 - acc: 0.8669\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.5689 - acc: 0.8780\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.5296 - acc: 0.8855\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.5004 - acc: 0.8922\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.4735 - acc: 0.8971\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.4495 - acc: 0.9030\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.4301 - acc: 0.9076\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.4120 - acc: 0.9121\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.3959 - acc: 0.9155\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.3810 - acc: 0.9205\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.3668 - acc: 0.9225\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.3547 - acc: 0.9249\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.3429 - acc: 0.9286\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.3317 - acc: 0.9305\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.3233 - acc: 0.9333\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.3146 - acc: 0.9359\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.3071 - acc: 0.9379\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.3001 - acc: 0.9389\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.2924 - acc: 0.9410\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.2856 - acc: 0.9424\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.2791 - acc: 0.9436\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.2736 - acc: 0.9451\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.2685 - acc: 0.9459\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.2639 - acc: 0.9461\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.2585 - acc: 0.9471\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.2544 - acc: 0.9489\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.2509 - acc: 0.9486\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.2463 - acc: 0.9500\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.2427 - acc: 0.9507\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.2395 - acc: 0.9517\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.2361 - acc: 0.9514\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.2331 - acc: 0.9526\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.2302 - acc: 0.9522\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.2271 - acc: 0.9536\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.2244 - acc: 0.9541\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.2219 - acc: 0.9540\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.2195 - acc: 0.9545\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.2172 - acc: 0.9550\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.2145 - acc: 0.9559\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.2128 - acc: 0.9550\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.2103 - acc: 0.9559\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.2079 - acc: 0.9572\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.2057 - acc: 0.9569\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.2036 - acc: 0.9577\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.2021 - acc: 0.9579\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.2004 - acc: 0.9580\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1988 - acc: 0.9582\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1969 - acc: 0.9585\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1955 - acc: 0.9586\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1939 - acc: 0.9591\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.1927 - acc: 0.9589\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1910 - acc: 0.9597\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1895 - acc: 0.9595\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1884 - acc: 0.9595\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1870 - acc: 0.9601\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1856 - acc: 0.9610\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1841 - acc: 0.9609\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1830 - acc: 0.9606\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1816 - acc: 0.9611\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1804 - acc: 0.9612\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1792 - acc: 0.9614\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1781 - acc: 0.9619\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1770 - acc: 0.9619\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1758 - acc: 0.9620\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1748 - acc: 0.9624\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1737 - acc: 0.9630\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1727 - acc: 0.9626\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1718 - acc: 0.9629\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.1708 - acc: 0.9631\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.1701 - acc: 0.9628\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1690 - acc: 0.9635\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1682 - acc: 0.9634\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1674 - acc: 0.9634\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1664 - acc: 0.9634\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1654 - acc: 0.9635\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.1646 - acc: 0.9641\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1637 - acc: 0.9640\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1630 - acc: 0.9644\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1624 - acc: 0.9645\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1613 - acc: 0.9646\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1605 - acc: 0.9645\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.1597 - acc: 0.9646\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.1589 - acc: 0.9647\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1581 - acc: 0.9647\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1574 - acc: 0.9649\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1568 - acc: 0.9649\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1562 - acc: 0.9653\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1555 - acc: 0.9657\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1546 - acc: 0.9658\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.1538 - acc: 0.9661\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1531 - acc: 0.9660\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.1525 - acc: 0.9659\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.1518 - acc: 0.9663\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 0.1512 - acc: 0.9660\n",
      "2000/2000 [==============================] - 0s 47us/step\n",
      "[0.36217639374732974, 0.8915]\n"
     ]
    }
   ],
   "source": [
    "#set model\n",
    "n_in = len(X[0])\n",
    "n_hidden = 200\n",
    "n_out = len(Y[0])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(n_hidden, input_dim = n_in))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.add(Dense(n_out))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = SGD(lr = 0.01),\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "#learning model\n",
    "epochs = 100\n",
    "batch_size = 200\n",
    "\n",
    "model.fit(X_train, Y_train, epochs = epochs, batch_size = batch_size)\n",
    "\n",
    "#evaluate\n",
    "loss_and_metrics = model.evaluate(X_test, Y_test)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 2.3119 - acc: 0.1406\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.1840 - acc: 0.3124\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.1003 - acc: 0.4886\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.0226 - acc: 0.5795\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.9503 - acc: 0.6507\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.8804 - acc: 0.6895\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.8110 - acc: 0.7086\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.7413 - acc: 0.7342\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.6721 - acc: 0.7526\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.6051 - acc: 0.7632\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.5401 - acc: 0.7771\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.4764 - acc: 0.7902\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.4145 - acc: 0.7961\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.3561 - acc: 0.8086\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.3004 - acc: 0.8180\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.2473 - acc: 0.8234\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.1969 - acc: 0.8326\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 1.1490 - acc: 0.8366\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.1035 - acc: 0.8395\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.0597 - acc: 0.8480\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.0185 - acc: 0.8500\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.9798 - acc: 0.8573\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.9430 - acc: 0.8601\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.9089 - acc: 0.8640\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.8768 - acc: 0.8684\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 0s 15us/step - loss: 0.8468 - acc: 0.8721\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.8186 - acc: 0.8746\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 0.7922 - acc: 0.8777\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.7669 - acc: 0.8801\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.7433 - acc: 0.8815\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.7212 - acc: 0.8841\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.7006 - acc: 0.8859\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.6805 - acc: 0.8880\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.6617 - acc: 0.8907\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.6439 - acc: 0.8925\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.6275 - acc: 0.8939\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.6113 - acc: 0.8962\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.5967 - acc: 0.8975\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.5823 - acc: 0.8985\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.5687 - acc: 0.8977\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.5559 - acc: 0.9012\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.5438 - acc: 0.9021\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.5321 - acc: 0.9037\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.5209 - acc: 0.9039\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.5106 - acc: 0.9054\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.5002 - acc: 0.9075\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.4906 - acc: 0.9094\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.4811 - acc: 0.9101\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.4724 - acc: 0.9101\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.4639 - acc: 0.9115\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.4557 - acc: 0.9125\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.4479 - acc: 0.9123\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.4402 - acc: 0.9135\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 0.4328 - acc: 0.9138\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.4260 - acc: 0.9149\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.4193 - acc: 0.9160\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.4131 - acc: 0.9168\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.4069 - acc: 0.9169\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.4012 - acc: 0.9173\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.3958 - acc: 0.9185\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 0.3901 - acc: 0.9191\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.3851 - acc: 0.9189\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.3799 - acc: 0.9204\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 0.3749 - acc: 0.9211\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.3706 - acc: 0.9211\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.3662 - acc: 0.9220\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.3618 - acc: 0.9221\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.3576 - acc: 0.9230\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.3535 - acc: 0.9228\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.3496 - acc: 0.9241\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 0.3460 - acc: 0.9242\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.3423 - acc: 0.9251\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.3385 - acc: 0.9255\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.3351 - acc: 0.9259\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.3319 - acc: 0.9258\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.3286 - acc: 0.9265\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.3254 - acc: 0.9266\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.3225 - acc: 0.9276\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.3193 - acc: 0.9279\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.3167 - acc: 0.9283\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.3139 - acc: 0.9289\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.3111 - acc: 0.9286\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.3087 - acc: 0.9293\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.3060 - acc: 0.9304\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.3034 - acc: 0.9305\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.3010 - acc: 0.9309\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.2985 - acc: 0.9321\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.2961 - acc: 0.9317\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.2940 - acc: 0.9321\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.2918 - acc: 0.9333\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.2896 - acc: 0.9332\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.2878 - acc: 0.9337\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.2856 - acc: 0.9334\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.2837 - acc: 0.9343\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.2819 - acc: 0.9332\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.2798 - acc: 0.9346\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.2780 - acc: 0.9350\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.2763 - acc: 0.9361\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.2745 - acc: 0.9355\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.2726 - acc: 0.9361\n",
      "2000/2000 [==============================] - 0s 55us/step\n",
      "[0.4238602936267853, 0.8835]\n"
     ]
    }
   ],
   "source": [
    "# add hidden layer\n",
    "#set model\n",
    "n_in = len(X[0])\n",
    "n_hidden = 200\n",
    "n_out = len(Y[0])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(n_hidden, input_dim = n_in))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.add(Dense(n_hidden))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.add(Dense(n_out))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = SGD(lr = 0.01),\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "#learning model\n",
    "epochs = 100\n",
    "batch_size = 200\n",
    "\n",
    "model.fit(X_train, Y_train, epochs = epochs, batch_size = batch_size)\n",
    "\n",
    "#evaluate\n",
    "loss_and_metrics = model.evaluate(X_test, Y_test)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 0s 37us/step - loss: 2.3757 - acc: 0.1109\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2931 - acc: 0.1326\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2862 - acc: 0.1262\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2800 - acc: 0.1403\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2739 - acc: 0.1429\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2682 - acc: 0.1491\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2620 - acc: 0.1801\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2562 - acc: 0.2140\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2497 - acc: 0.1961\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2431 - acc: 0.2351\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2366 - acc: 0.2114\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2297 - acc: 0.2774\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2228 - acc: 0.2936\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2157 - acc: 0.3070\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2083 - acc: 0.3675\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2001 - acc: 0.3926\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.1920 - acc: 0.3802\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.1833 - acc: 0.4213\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.1743 - acc: 0.4261\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.1652 - acc: 0.4796\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.1552 - acc: 0.4946\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.1448 - acc: 0.5104\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.1340 - acc: 0.5213\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.1223 - acc: 0.5330\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.1105 - acc: 0.5732\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.0978 - acc: 0.5604\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.0842 - acc: 0.5849\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.0700 - acc: 0.6034\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.0551 - acc: 0.5959\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.0395 - acc: 0.5902\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.0230 - acc: 0.6168\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.0055 - acc: 0.6315\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 1.9870 - acc: 0.6400\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.9677 - acc: 0.6216\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.9473 - acc: 0.6490\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 1.9263 - acc: 0.6435\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 1.9043 - acc: 0.6430\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.8812 - acc: 0.6522\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 1.8577 - acc: 0.6596\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.8332 - acc: 0.6572\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 1.8078 - acc: 0.6743\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 1.7820 - acc: 0.6612\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 1.7555 - acc: 0.6646\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 1.7283 - acc: 0.6867\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.7005 - acc: 0.6685\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 1.6727 - acc: 0.6862\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.6446 - acc: 0.6831\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 1.6166 - acc: 0.6926\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.5879 - acc: 0.6866\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.5599 - acc: 0.6935\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 1.5324 - acc: 0.7058\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.5044 - acc: 0.7064\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.4773 - acc: 0.7101\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.4509 - acc: 0.7165\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 1.4249 - acc: 0.7200\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.3993 - acc: 0.7220\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.3741 - acc: 0.7228\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.3497 - acc: 0.7369\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 1.3259 - acc: 0.7329\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.3024 - acc: 0.7417\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.2799 - acc: 0.7361\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.2574 - acc: 0.7471\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.2362 - acc: 0.7528\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 1.2151 - acc: 0.7570\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 1.1947 - acc: 0.7599\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.1747 - acc: 0.7684\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.1551 - acc: 0.7551\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.1365 - acc: 0.7810\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.1180 - acc: 0.7770\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.1000 - acc: 0.7735\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.0826 - acc: 0.7859\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.0657 - acc: 0.7799\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.0489 - acc: 0.7881\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.0327 - acc: 0.7921\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 1.0166 - acc: 0.7936\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 1.0010 - acc: 0.7948\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.9856 - acc: 0.7961\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.9710 - acc: 0.8056\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.9566 - acc: 0.8064\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.9425 - acc: 0.8121\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.9286 - acc: 0.8139\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.9149 - acc: 0.8165\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.9017 - acc: 0.8190\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.8887 - acc: 0.8201\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.8761 - acc: 0.8241\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.8636 - acc: 0.8246\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.8512 - acc: 0.8254\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.8396 - acc: 0.8309\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.8280 - acc: 0.8335\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.8167 - acc: 0.8341\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.8058 - acc: 0.8361\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.7949 - acc: 0.8383\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.7844 - acc: 0.8392\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 0.7740 - acc: 0.8404\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.7638 - acc: 0.8430\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.7540 - acc: 0.8439\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.7442 - acc: 0.8498\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.7348 - acc: 0.8493\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.7256 - acc: 0.8506\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 0.7164 - acc: 0.8511\n",
      "2000/2000 [==============================] - 0s 47us/step\n",
      "[0.792951337814331, 0.8015]\n"
     ]
    }
   ],
   "source": [
    "# add hidden layer\n",
    "#set model\n",
    "n_in = len(X[0])\n",
    "n_hidden = 200\n",
    "n_out = len(Y[0])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(n_hidden, input_dim = n_in))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.add(Dense(n_hidden))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.add(Dense(n_hidden))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.add(Dense(n_out))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = SGD(lr = 0.01),\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "#learning model\n",
    "epochs = 100\n",
    "batch_size = 200\n",
    "\n",
    "model.fit(X_train, Y_train, epochs = epochs, batch_size = batch_size)\n",
    "\n",
    "#evaluate\n",
    "loss_and_metrics = model.evaluate(X_test, Y_test)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 0s 43us/step - loss: 2.3490 - acc: 0.0972\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2999 - acc: 0.1153\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2991 - acc: 0.1145\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2985 - acc: 0.1152\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2981 - acc: 0.1152\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2976 - acc: 0.1152\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2972 - acc: 0.1153\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2970 - acc: 0.1156\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2965 - acc: 0.1159\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2959 - acc: 0.1152\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2954 - acc: 0.1154\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2949 - acc: 0.1153\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2945 - acc: 0.1153\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2940 - acc: 0.1166\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2937 - acc: 0.1153\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2931 - acc: 0.1215\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2926 - acc: 0.1162\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2923 - acc: 0.1153\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2918 - acc: 0.1152\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2913 - acc: 0.1160\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2906 - acc: 0.1264\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2903 - acc: 0.1152\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2894 - acc: 0.1259\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2892 - acc: 0.1156\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2885 - acc: 0.1170\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2880 - acc: 0.1174\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2874 - acc: 0.1152\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2868 - acc: 0.1152\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2864 - acc: 0.1210\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2857 - acc: 0.1155\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2854 - acc: 0.1180\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2847 - acc: 0.1176\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2842 - acc: 0.1159\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2836 - acc: 0.1155\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2826 - acc: 0.1154\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2822 - acc: 0.1153\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2815 - acc: 0.1177\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2807 - acc: 0.1154\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2802 - acc: 0.1191\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2796 - acc: 0.1301\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2787 - acc: 0.1153\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2777 - acc: 0.1260\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2773 - acc: 0.1289\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2765 - acc: 0.1173\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2758 - acc: 0.1221\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2749 - acc: 0.1208\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2739 - acc: 0.1248\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2728 - acc: 0.1209\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2722 - acc: 0.1768\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 0s 18us/step - loss: 2.2710 - acc: 0.1437\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2706 - acc: 0.1290\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2692 - acc: 0.1171\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2684 - acc: 0.1384\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2673 - acc: 0.1231\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2663 - acc: 0.1274\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2652 - acc: 0.1343\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2640 - acc: 0.1820\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2629 - acc: 0.1184\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2616 - acc: 0.1344\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2604 - acc: 0.1510\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2595 - acc: 0.1646\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2578 - acc: 0.1681\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2565 - acc: 0.1709\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2551 - acc: 0.1724\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2537 - acc: 0.1341\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2519 - acc: 0.1565\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2504 - acc: 0.1794\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2487 - acc: 0.1615\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2470 - acc: 0.2030\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2451 - acc: 0.1814\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2431 - acc: 0.2172\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2414 - acc: 0.2125\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2393 - acc: 0.1704\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2373 - acc: 0.2349\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2351 - acc: 0.2356\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2327 - acc: 0.2224\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2302 - acc: 0.2300\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2277 - acc: 0.2905\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2252 - acc: 0.2765\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2225 - acc: 0.2669\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2196 - acc: 0.2749\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2165 - acc: 0.2793\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2135 - acc: 0.2866\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.2103 - acc: 0.3400\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2067 - acc: 0.2926\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.2032 - acc: 0.3329\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 0s 18us/step - loss: 2.1994 - acc: 0.3266\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.1952 - acc: 0.3565\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.1911 - acc: 0.3690\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.1866 - acc: 0.3594\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.1819 - acc: 0.3591\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.1770 - acc: 0.3485\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 2.1719 - acc: 0.3936\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.1665 - acc: 0.3844\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.1607 - acc: 0.4120\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.1548 - acc: 0.4131\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.1486 - acc: 0.3943\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.1418 - acc: 0.4172\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.1348 - acc: 0.4066\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.1276 - acc: 0.4451\n",
      "2000/2000 [==============================] - 0s 62us/step\n",
      "[2.12197421836853, 0.4415]\n"
     ]
    }
   ],
   "source": [
    "# add hidden layer\n",
    "#set model\n",
    "n_in = len(X[0])\n",
    "n_hidden = 200\n",
    "n_out = len(Y[0])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(n_hidden, input_dim = n_in))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.add(Dense(n_hidden))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.add(Dense(n_hidden))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.add(Dense(n_hidden))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.add(Dense(n_out))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = SGD(lr = 0.01),\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "#learning model\n",
    "epochs = 100\n",
    "batch_size = 200\n",
    "\n",
    "model.fit(X_train, Y_train, epochs = epochs, batch_size = batch_size)\n",
    "\n",
    "#evaluate\n",
    "loss_and_metrics = model.evaluate(X_test, Y_test)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
